{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TvyemfDlDmu"
   },
   "source": [
    "### Coursework coding instructions (please also see full coursework spec)\n",
    "\n",
    "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
    "\n",
    "For the task you choose you will need to do two approaches:\n",
    "  - Approach 1, which can use use pre-trained embeddings / models\n",
    "  - Approach 2, which should not use any pre-trained embeddings or models\n",
    "We should be able to run both approaches from the same colab file\n",
    "\n",
    "#### Running your code:\n",
    "  - Your models should run automatically when running your colab file without further intervention\n",
    "  - For each task you should automatically output the performance of both models\n",
    "  - Your code should automatically download any libraries required\n",
    "\n",
    "#### Structure of your code:\n",
    "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
    "  - Otherwise there are no restrictions on what you can do in your code\n",
    "\n",
    "#### Documentation:\n",
    "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
    "\n",
    "#### Reproducibility:\n",
    "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
    "\n",
    "Good luck! We are really looking forward to seeing your reports and your model code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRWFk-kelDoA",
    "outputId": "6ea12635-b240-470f-d32b-d3fb8b949704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-01 09:46:40--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-03-01 09:46:40--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-03-01 09:46:40--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip.1’\n",
      "\n",
      "glove.6B.zip.1        7%[>                   ]  58.00M  2.12MB/s    eta 6m 25s ^C\n",
      "Archive:  glove.6B.zip\n",
      "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "# You will need to download any word embeddings required for your code, e.g.:\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip\n",
    "!pip install transformers\n",
    "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
    "\n",
    "#! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_jkkPTtWZel",
    "outputId": "6135a878-0479-493d-fed1-376a08285823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WX9TqmK7lDoK"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import codecs\n",
    "import transformers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "X09jt8VRlDoM"
   },
   "outputs": [],
   "source": [
    "# Setting random seed and device\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqhlzLl6lDoO"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('./drive/MyDrive/Colab Notebooks/Imperial - NLP/data/train.csv')\n",
    "dev_df = pd.read_csv('./drive/MyDrive/Colab Notebooks/Imperial - NLP/data/dev.csv')\n",
    "test_df = pd.read_csv('./drive/MyDrive/Colab Notebooks/Imperial - NLP/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3uCjTpRnfG5a"
   },
   "outputs": [],
   "source": [
    "# replace original word with edited word\n",
    "def get_edited_df(df):\n",
    "    df_copy = df.copy(deep=True)\n",
    "    df_copy['edited'] = df_copy['original']\n",
    "    df_copy['edited'] = df_copy.apply(lambda x: re.sub(r\"(<[^>]+>)\", x['edit'], x['edited']), axis=1)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_LEL30MdJSRW"
   },
   "outputs": [],
   "source": [
    "train_df = get_edited_df(train_df)\n",
    "dev_df = get_edited_df(dev_df)\n",
    "test_df = get_edited_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p_0gbHc9JSRW"
   },
   "outputs": [],
   "source": [
    "# Datasets for approach 2\n",
    "edited_train_df = get_edited_df(train_df)\n",
    "edited_dev_df = get_edited_df(dev_df)\n",
    "edited_test_df = get_edited_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3RCmF7xulDoP"
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Proportion of training data for train compared to dev\n",
    "train_proportion = 0.8\n",
    "\n",
    "# batch_size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qAgZW6K1lDoR"
   },
   "outputs": [],
   "source": [
    "# We define our training loop\n",
    "def train(train_iter, dev_iter, model, number_epoch, method=None, filename=None):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print(\"Training model.\")\n",
    "    if method == 'bert':\n",
    "        train_loss = []\n",
    "        eval_loss = []\n",
    "\n",
    "        for epoch in range(1, number_epoch+1):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_sse = 0\n",
    "            no_observations = 0\n",
    "\n",
    "            for batch in train_iter:\n",
    "                feature, target, mask = batch\n",
    "                \n",
    "                feature, target, mask = feature.to(device), target.to(device), mask.to(device)\n",
    "                model.batch_size = target.shape[0]\n",
    "                no_observations += target.shape[0]\n",
    "                output = model(feature, attention_mask=mask, labels=target)\n",
    "                predictions = output.logits.squeeze(1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = loss_fn(predictions, target)\n",
    "\n",
    "                sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()*target.shape[0]\n",
    "                epoch_sse += sse\n",
    "            \n",
    "            valid_loss, valid_mse, __, __ = eval(dev_iter, model, method=method)\n",
    "\n",
    "            epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "            \n",
    "            train_loss += [epoch_loss]\n",
    "            eval_loss += [valid_loss]\n",
    "            \n",
    "            print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "            Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
    "        torch.save(model.state_dict(), './drive/MyDrive/NLP_CW/bert.pth')\n",
    "        np.save('./drive/MyDrive/NLP_CW/train_loss.npy', train_loss)\n",
    "        np.save('./drive/MyDrive/NLP_CW/eval_loss.npy', eval_loss)\n",
    "    elif method == 'attn':\n",
    "        train_losses = []\n",
    "        eval_losses = []\n",
    "        train_mse = []\n",
    "        eval_mse = []\n",
    "\n",
    "        for epoch in range(1, number_epoch+1):\n",
    "\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_sse = 0\n",
    "            no_observations = 0  # Observations used for training so far\n",
    "\n",
    "            for batch in train_iter:\n",
    "\n",
    "                feature, target = batch\n",
    "\n",
    "                feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "                # for RNN:\n",
    "                model.batch_size = target.shape[0]\n",
    "                no_observations = no_observations + target.shape[0]\n",
    "                #model.hidden = model.init_hidden()\n",
    "\n",
    "                predictions = model(feature).squeeze(1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss = loss_fn(predictions, target)\n",
    "\n",
    "                sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()*target.shape[0]\n",
    "                epoch_sse += sse\n",
    "\n",
    "            valid_loss, valid_mse, __, __ = eval(dev_iter, model, method=method)\n",
    "            epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "\n",
    "            train_losses.append(epoch_loss)\n",
    "            eval_losses.append(valid_loss)\n",
    "            train_mse.append(epoch_mse)\n",
    "            eval_mse.append(valid_mse)\n",
    "            \n",
    "            print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "            Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
    "        \n",
    "        #torch.save(model.state_dict(), './drive/MyDrive/Colab Notebooks/Imperial - NLP/model.pth')\n",
    "\n",
    "        return train_losses, eval_losses, train_mse, eval_mse\n",
    "\n",
    "    else:\n",
    "        train_loss = []\n",
    "        eval_loss = []\n",
    "        for epoch in range(1, number_epoch+1):\n",
    "\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_sse = 0\n",
    "            no_observations = 0  # Observations used for training so far\n",
    "\n",
    "            for batch in train_iter:\n",
    "\n",
    "                feature, target = batch\n",
    "\n",
    "                feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "                model.batch_size = target.shape[0]\n",
    "                no_observations = no_observations + target.shape[0]\n",
    "                model.hidden = model.init_hidden()\n",
    "\n",
    "                predictions = model(feature).squeeze(1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss = loss_fn(predictions, target)\n",
    "\n",
    "                sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()*target.shape[0]\n",
    "                epoch_sse += sse\n",
    "\n",
    "            valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
    "\n",
    "            epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "            train_loss += [epoch_loss]\n",
    "            eval_loss += [valid_loss]\n",
    "            print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "            Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
    "    \n",
    "        # torch.save(model.state_dict(), './bigru.pth')\n",
    "        if len(filename) > 1:\n",
    "            np.save(filename[0], train_loss)\n",
    "            np.save(filename[1], eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NzXeDgHmlDob"
   },
   "outputs": [],
   "source": [
    "# We evaluate performance on our dev set\n",
    "def eval(data_iter, model, method=None):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    if method == 'bert':\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        pred_all = []\n",
    "        trg_all = []\n",
    "        no_observations = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in data_iter:\n",
    "                feature, target, mask = batch\n",
    "\n",
    "                feature, target, mask = feature.to(device), target.to(device), mask.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "                model.batch_size = target.shape[0]\n",
    "                no_observations = no_observations + target.shape[0]\n",
    "                output = model(feature, attention_mask=mask, labels=target)\n",
    "                predictions = output.logits.squeeze(1)\n",
    "\n",
    "                loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "                pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "                sse, __ = model_performance(pred, trg)\n",
    "\n",
    "                epoch_loss += loss.item()*target.shape[0]\n",
    "                epoch_sse += sse\n",
    "                pred_all.extend(pred)\n",
    "                trg_all.extend(trg)\n",
    "    \n",
    "    elif method == 'attn':\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        pred_all = []\n",
    "        trg_all = []\n",
    "        no_observations = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in data_iter:\n",
    "                feature, target = batch\n",
    "\n",
    "                feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "                # for RNN:\n",
    "                model.batch_size = target.shape[0]\n",
    "                no_observations = no_observations + target.shape[0]\n",
    "                #model.hidden = model.init_hidden()\n",
    "\n",
    "                predictions = model(feature).squeeze(1)\n",
    "                loss = loss_fn(predictions, target)\n",
    "\n",
    "                # We get the mse\n",
    "                pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "                sse, __ = model_performance(pred, trg)\n",
    "\n",
    "                epoch_loss += loss.item()*target.shape[0]\n",
    "                epoch_sse += sse\n",
    "                pred_all.extend(pred)\n",
    "                trg_all.extend(trg)\n",
    "\n",
    "        return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)\n",
    "\n",
    "    else:\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        pred_all = []\n",
    "        trg_all = []\n",
    "        no_observations = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in data_iter:\n",
    "                feature, target = batch\n",
    "\n",
    "                feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "                model.batch_size = target.shape[0]\n",
    "                no_observations = no_observations + target.shape[0]\n",
    "                model.hidden = model.init_hidden()\n",
    "\n",
    "                predictions = model(feature).squeeze(1)\n",
    "                loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "                pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "                sse, __ = model_performance(pred, trg)\n",
    "\n",
    "                epoch_loss += loss.item()*target.shape[0]\n",
    "                epoch_sse += sse\n",
    "                pred_all.extend(pred)\n",
    "                trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2_22fHHElDog"
   },
   "outputs": [],
   "source": [
    "# How we print the model performance\n",
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
    "    \"\"\"\n",
    "\n",
    "    sq_error = (output - target)**2\n",
    "\n",
    "    sse = np.sum(sq_error)\n",
    "    mse = np.mean(sq_error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
    "\n",
    "    return sse, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LcxmqrKhlDoj"
   },
   "outputs": [],
   "source": [
    "def create_vocab(data):\n",
    "    \"\"\"\n",
    "    Creating a corpus of all the tokens used\n",
    "    \"\"\"\n",
    "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
    "\n",
    "    for sentence in data:\n",
    "\n",
    "        tokenized_sentence = []\n",
    "\n",
    "        for token in sentence.split(' '): # simplest split is\n",
    "\n",
    "            tokenized_sentence.append(token)\n",
    "\n",
    "        tokenized_corpus.append(tokenized_sentence)\n",
    "\n",
    "    # Create single list of all vocabulary\n",
    "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
    "\n",
    "    for sentence in tokenized_corpus:\n",
    "\n",
    "        for token in sentence:\n",
    "\n",
    "            if token not in vocabulary:\n",
    "\n",
    "                if True:\n",
    "                    vocabulary.append(token)\n",
    "\n",
    "    return vocabulary, tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jzQ0KLXslDoq"
   },
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    We add padding to our minibatches and create tensors for our model\n",
    "    '''\n",
    "\n",
    "    batch_labels = [l for f, l in batch]\n",
    "    batch_features = [f for f, l in batch]\n",
    "\n",
    "    batch_features_len = [len(f) for f, l in batch]\n",
    "\n",
    "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
    "\n",
    "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
    "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "\n",
    "    batch_labels = torch.FloatTensor(batch_labels)\n",
    "\n",
    "    return seq_tensor, batch_labels\n",
    "\n",
    "class Task1DatasetBert(Dataset):\n",
    "\n",
    "    def __init__(self, train_data, labels, mask):\n",
    "        self.x_train = train_data\n",
    "        self.y_train = labels\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_train[item], self.y_train[item], self.mask[item]\n",
    "\n",
    "class Task1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_data, labels):\n",
    "        self.x_train = train_data\n",
    "        self.y_train = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_train[item], self.y_train[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUh8YSF1YGB3"
   },
   "source": [
    "# Part 1 First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sWaxTh2UlDoy"
   },
   "outputs": [],
   "source": [
    "class attBiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
    "        super(attBiLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, dropout=0.3)\n",
    "        self.label = nn.Linear(hidden_dim* 2, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def attNetwork(self, x, query):\n",
    "\n",
    "        query_dim = query.size(-1)\n",
    "        alpha = torch.matmul(query, x.transpose(1, 2) / math.sqrt(query_dim))\n",
    "\n",
    "        attn = F.softmax(alpha, dim = -1)\n",
    "        context = torch.matmul(attn, x).sum(1)\n",
    "\n",
    "        return context, attn\n",
    "\n",
    "    def forward(self, sentence):             \n",
    "        embedding = self.dropout(self.embedding(sentence))\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(embedding)\n",
    "\n",
    "        query = self.dropout(output)\n",
    "        attn_output, attn = self.attNetwork(output, query)\n",
    "        logit = self.label(attn_output)\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tesg49NyCB3v",
    "outputId": "7788586d-267b-475b-9c4f-8a52da98684b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab created.\n"
     ]
    }
   ],
   "source": [
    "## Approach 1 code, using functions defined above:\n",
    "\n",
    "# We set our training data and test data\n",
    "training_data = train_df['edited']\n",
    "test_data = dev_df['edited']\n",
    "\n",
    "# Creating word vectors\n",
    "training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
    "test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
    "\n",
    "# Creating joint vocab from test and train:\n",
    "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\n",
    "\n",
    "print(\"Vocab created.\")\n",
    "\n",
    "# We create representations for our tokens\n",
    "wvecs = [] # word vectors\n",
    "word2idx = [] # word2index\n",
    "idx2word = []\n",
    "\n",
    "# This is a large file, it will take a while to load in the memory!\n",
    "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\n",
    "  index = 0\n",
    "  for line in f.readlines():\n",
    "    # Ignore the first line - first line typically contains vocab, dimensionality\n",
    "    if len(line.strip().split()) > 3:\n",
    "      word = line.strip().split()[0]\n",
    "      if word in joint_vocab:\n",
    "          (word, vec) = (word,\n",
    "                     list(map(float,line.strip().split()[1:])))\n",
    "          wvecs.append(vec)\n",
    "          word2idx.append((word, index))\n",
    "          idx2word.append((index, word))\n",
    "          index += 1\n",
    "\n",
    "wvecs = np.array(wvecs)\n",
    "word2idx = dict(word2idx)\n",
    "idx2word = dict(idx2word)\n",
    "\n",
    "vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in training_tokenized_corpus]\n",
    "\n",
    "# To avoid any sentences being empty (if no words match to our word embeddings)\n",
    "vectorized_seqs = [x if len(x) > 0 else [0] for x in vectorized_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5tNHPq5CGma",
    "outputId": "99be170a-105f-4e5e-cacf-81594f9bc5d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialised.\n",
      "Dataloaders created.\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |             Val. Loss: 0.39 | Val. MSE: 0.39 |  Val. RMSE: 0.62 |\n",
      "| Epoch: 02 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |             Val. Loss: 0.39 | Val. MSE: 0.39 |  Val. RMSE: 0.63 |\n",
      "| Epoch: 03 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |             Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.62 |\n",
      "| Epoch: 04 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |             Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 05 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |             Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 06 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 07 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |             Val. Loss: 0.38 | Val. MSE: 0.38 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 08 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 09 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 10 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(word2idx)\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = attBiLSTM(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\n",
    "print(\"Model initialised.\")\n",
    "\n",
    "model.to(device)\n",
    "# We provide the model with our embeddings\n",
    "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
    "\n",
    "feature = vectorized_seqs\n",
    "\n",
    "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
    "train_and_dev = Task1Dataset(feature, train_df['meanGrade'])\n",
    "dev_dataset = Task1Dataset(feature, dev_df['meanGrade'])\n",
    "test_dataset = Task1Dataset(feature, test_df['meanGrade'])\n",
    "\n",
    "train_examples = round(len(train_and_dev)*train_proportion)\n",
    "dev_examples = len(train_and_dev) - train_examples\n",
    "\n",
    "train_dataset, dev_dataset = random_split(train_and_dev,\n",
    "                                           (train_examples,\n",
    "                                            dev_examples))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "print(\"Dataloaders created.\")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.02)\n",
    "\n",
    "train_losses, eval_losses, train_mse, eval_mse = train(train_loader, dev_loader, model, epochs, 'attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "DxcmnapxCOfj",
    "outputId": "ad11ad83-dc7b-4143-8359-94f2d40d0d4c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw training curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "x = list(range(len(train_losses)))\n",
    "plt.plot(x, train_losses)\n",
    "plt.plot(x, eval_losses)\n",
    "plt.legend(['train loss', 'eval loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qce-yvO2H2BX",
    "outputId": "6031a36d-db8d-4dae-8abd-3239fe980d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole test data, test loss0.381673, test rmse0.617797\n",
      "0.100000 test data, test loss0.950547, test rmse0.974960\n",
      "0.200000 test data, test loss0.673055, test rmse0.820399\n",
      "0.300000 test data, test loss0.549968, test rmse0.741598\n",
      "0.400000 test data, test loss0.457464, test rmse0.676361\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.sort_values(by=['meanGrade'])\n",
    "n_samples = test_df.shape[0]\n",
    "test10 = pd.concat([test_df[:int(0.1*n_samples)], test_df[int(0.9*n_samples):]], ignore_index=True)\n",
    "test20 = pd.concat([test_df[:int(0.2*n_samples)], test_df[int(0.8*n_samples):]], ignore_index=True)\n",
    "test30 = pd.concat([test_df[:int(0.3*n_samples)], test_df[int(0.7*n_samples):]], ignore_index=True)\n",
    "test40 = pd.concat([test_df[:int(0.4*n_samples)], test_df[int(0.6*n_samples):]], ignore_index=True)\n",
    "\n",
    "test10_dataset = Task1Dataset(feature, test10['meanGrade'])\n",
    "test20_dataset = Task1Dataset(feature, test20['meanGrade'])\n",
    "test30_dataset = Task1Dataset(feature, test30['meanGrade'])\n",
    "test40_dataset = Task1Dataset(feature, test40['meanGrade'])\n",
    "\n",
    "test_loader10 = torch.utils.data.DataLoader(test10_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "test_loader20 = torch.utils.data.DataLoader(test20_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "test_loader30 = torch.utils.data.DataLoader(test30_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "test_loader40 = torch.utils.data.DataLoader(test40_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "loaders = [test_loader, test_loader10, test_loader20, test_loader30, test_loader40]\n",
    "\n",
    "#test_loss, test_mse, __, __ = eval(test_loader10, model)\n",
    "for i, loader in enumerate(loaders):\n",
    "    test_loss, test_mse, __, __ = eval(loader, model, 'attn')\n",
    "    if i == 0:\n",
    "        print('whole test data, test loss{:.6f}, test rmse{:.6f}'.format(test_loss, test_mse**0.5))\n",
    "    else:\n",
    "        print('{:2f} test data, test loss{:.6f}, test rmse{:.6f}'.format(0.1*i, test_loss, test_mse**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMKhSKhmEO4h"
   },
   "source": [
    "# Part 1 Second Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ydKdP6tly1k",
    "outputId": "046a1a65-e91e-406f-9c1f-055c4effb0e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "setence tokenized and padded.\n",
      "data loader created.\n"
     ]
    }
   ],
   "source": [
    "MaxLen = 40\n",
    "\n",
    "# create dataloader\n",
    "def create_dataloader(df):\n",
    "    data = df['edited']\n",
    "    model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    data_tokenized = data.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "    data_tokenized = pad_sequences(data_tokenized, maxlen=MaxLen, dtype='long', value=0, truncating='post')\n",
    "    print('setence tokenized and padded.')\n",
    "    attention_mask = []\n",
    "    for token in data_tokenized:\n",
    "        att_mask = [int(token_id > 0) for token_id in token]\n",
    "        attention_mask.append(att_mask)\n",
    "\n",
    "    data_tokenized = torch.tensor(data_tokenized)\n",
    "    label = torch.tensor(df['meanGrade'].values, dtype=torch.float32)\n",
    "    attention_mask = torch.tensor(attention_mask, dtype=torch.int32)\n",
    "    dataset = Task1DatasetBert(data_tokenized, label, attention_mask)\n",
    "    loader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "    print('data loader created.')\n",
    "    return loader\n",
    "\n",
    "train_loader = create_dataloader(train_df)\n",
    "dev_loader = create_dataloader(dev_df)\n",
    "test_loader = create_dataloader(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9paRh4jFI3_X",
    "outputId": "057cf0e3-6f1f-44b7-ead4-24d6a1998591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "setence tokenized and padded.\n",
      "data loader created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |             Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 02 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |             Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 03 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |             Val. Loss: 0.31 | Val. MSE: 0.31 |  Val. RMSE: 0.56 |\n",
      "| Epoch: 04 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 05 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |             Val. Loss: 0.31 | Val. MSE: 0.31 |  Val. RMSE: 0.56 |\n",
      "| Epoch: 06 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |             Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |             Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |             Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |             Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n"
     ]
    }
   ],
   "source": [
    "# define and train model\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                                   num_labels=1,\n",
    "                                                                   output_attentions=False,\n",
    "                                                                   output_hidden_states=False)\n",
    "model.hidden_dropout_prob = 0.3\n",
    "model.attention_dropout_prob = 0.3\n",
    "model.cuda()\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.03)\n",
    "\n",
    "train(train_loader, dev_loader, model, epochs, 'bert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1o2OF5W4Ynh",
    "outputId": "159d20e5-ec69-4d54-ac6c-e32949b43e25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "setence tokenized and padded.\n",
      "data loader created.\n",
      "whole test data, test loss0.317227, test rmse0.563229\n",
      "0.100000 test data, test loss0.879384, test rmse0.937755\n",
      "0.200000 test data, test loss0.630693, test rmse0.794162\n",
      "0.300000 test data, test loss0.483561, test rmse0.695385\n",
      "0.400000 test data, test loss0.386061, test rmse0.621338\n"
     ]
    }
   ],
   "source": [
    "model = transformers.BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                                   num_labels=1,\n",
    "                                                                   output_attentions=False,\n",
    "                                                                   output_hidden_states=False)\n",
    "model.load_state_dict(torch.load('./drive/MyDrive/NLP_CW/bert.pth'))\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "test_df = test_df.sort_values(by=['meanGrade'])\n",
    "n_samples = test_df.shape[0]\n",
    "test10 = pd.concat([test_df[:int(0.1*n_samples)], test_df[int(0.9*n_samples):]])\n",
    "test20 = pd.concat([test_df[:int(0.2*n_samples)], test_df[int(0.8*n_samples):]])\n",
    "test30 = pd.concat([test_df[:int(0.3*n_samples)], test_df[int(0.7*n_samples):]])\n",
    "test40 = pd.concat([test_df[:int(0.4*n_samples)], test_df[int(0.6*n_samples):]])\n",
    "\n",
    "test_loader10 = create_dataloader(test10)\n",
    "test_loader20 = create_dataloader(test20)\n",
    "test_loader30 = create_dataloader(test30)\n",
    "test_loader40 = create_dataloader(test40)\n",
    "loaders = [test_loader, test_loader10, test_loader20, test_loader30, test_loader40]\n",
    "for i, loader in enumerate(loaders):\n",
    "    test_loss, test_mse, __, __ = eval(loader, model, 'bert')\n",
    "    if i == 0:\n",
    "        print('whole test data, test loss{:.6f}, test rmse{:.6f}'.format(test_loss, test_mse**0.5))\n",
    "    else:\n",
    "        print('{:2f} test data, test loss{:.6f}, test rmse{:.6f}'.format(0.1*i, test_loss, test_mse**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "1X15ozkg0Ts1",
    "outputId": "12f405e5-ce08-4730-b37d-6bd153b118b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw training curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "train_loss = np.load('./drive/MyDrive/NLP_CW/train_loss.npy')\n",
    "eval_loss = np.load('./drive/MyDrive/NLP_CW/eval_loss.npy')\n",
    "x = list(range(len(train_loss)))\n",
    "plt.plot(x, train_loss)\n",
    "plt.plot(x, eval_loss)\n",
    "plt.legend(['train loss', 'eval loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdeFaoc3lDpK"
   },
   "source": [
    "#### Approach 2: No pre-trained representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46gm47T4lDpQ",
    "outputId": "6675cde2-9bba-4955-a292-b78cc0f3e12c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train performance:\n",
      "| MSE: 0.13 | RMSE: 0.37 |\n",
      "\n",
      "Dev performance:\n",
      "| MSE: 0.36 | RMSE: 0.60 |\n"
     ]
    }
   ],
   "source": [
    "train_and_dev = train_df['edit']\n",
    "\n",
    "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
    "                                                                        test_size=(1-train_proportion),\n",
    "                                                                        random_state=42)\n",
    "\n",
    "# We train a Tf-idf model\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "train_counts = count_vect.fit_transform(training_data)\n",
    "transformer = TfidfTransformer().fit(train_counts)\n",
    "train_counts = transformer.transform(train_counts)\n",
    "regression_model = LinearRegression().fit(train_counts, training_y)\n",
    "\n",
    "# Train predictions\n",
    "predicted_train = regression_model.predict(train_counts)\n",
    "\n",
    "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
    "test_and_test_counts = count_vect.transform(train_and_dev)\n",
    "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
    "\n",
    "test_counts = count_vect.transform(dev_data)\n",
    "\n",
    "test_counts = transformer.transform(test_counts)\n",
    "\n",
    "# Dev predictions\n",
    "predicted = regression_model.predict(test_counts)\n",
    "\n",
    "# We run the evaluation:\n",
    "print(\"\\nTrain performance:\")\n",
    "sse, mse = model_performance(predicted_train, training_y, True)\n",
    "\n",
    "print(\"\\nDev performance:\")\n",
    "sse, mse = model_performance(predicted, dev_y, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HyHwHkUlDpa"
   },
   "source": [
    "#### Baseline for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DA3q4o1lDpd",
    "outputId": "fa88780f-7ed0-4c2b-f2cf-bc0b2883626d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline performance:\n",
      "| MSE: 0.34 | RMSE: 0.58 |\n"
     ]
    }
   ],
   "source": [
    "# Baseline for the task\n",
    "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
    "print(\"\\nBaseline performance:\")\n",
    "sse, mse = model_performance(pred_baseline, dev_y, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84nQDZyBlDpg"
   },
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyoTMOswJSR2"
   },
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1JSvTMg0JSR2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpbeetARJSR3"
   },
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VDbEfZnYJSR3"
   },
   "outputs": [],
   "source": [
    "# Load data from local\n",
    "train_df = pd.read_csv('./dataset/train.csv')\n",
    "dev_df = pd.read_csv('./dataset/dev.csv')\n",
    "test_df = pd.read_csv('./dataset/test.csv')\n",
    "edited_train_df = get_edited_df(train_df)\n",
    "edited_dev_df = get_edited_df(dev_df)\n",
    "edited_test_df = get_edited_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gMxbE7kxJSR3"
   },
   "outputs": [],
   "source": [
    "training_x = edited_train_df['edited']\n",
    "dev_x = edited_dev_df['edited']\n",
    "training_y= edited_train_df['meanGrade']\n",
    "dev_y = edited_dev_df['meanGrade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPEXUFtVJSR9"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QiilY8p7JSR9"
   },
   "outputs": [],
   "source": [
    "def get_tokenized_corpus(corpus):\n",
    "    \"\"\"\n",
    "    Return a list of tokenized sentences\n",
    "    \"\"\"\n",
    "    # tokenized the sentence\n",
    "    tokenized_sentence = [word_tokenize(s) for s in corpus] # list of list of sentences\n",
    "    \n",
    "    # remove the stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenized_sentence_filtered = []\n",
    "    # Lemmatizing and removing stopwords\n",
    "    for s in tokenized_sentence:\n",
    "        tokenized_sentence_filtered.append([WordNetLemmatizer().lemmatize(w.lower(), 'v') for w in s if w not in stop_words])\n",
    "    return tokenized_sentence_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7G2Hd6zkJSR_"
   },
   "outputs": [],
   "source": [
    "def load_data(data, context_size, subsampling=False, sampling_rate=1e-5):\n",
    "    \"\"\" Load a list of sentenses and return the training pairs after data preprocessing\n",
    "        \n",
    "    :param data: Input list of sentences\n",
    "    :param context_size: Window size for skip gram model\n",
    "    :param subsampling: bool\n",
    "    :param sampling_rate: subsampling rate\n",
    "          \n",
    "    :return train_idx_pairs: list of word pairs\n",
    "    :return vocabulary: dictionary of vocabulary\n",
    "    :return w2i: dictionary, word to index\n",
    "    :return i2w: dictionary, index to word\n",
    "    \"\"\"\n",
    "    # tokenized the sentence\n",
    "    tokenized_sentence = [word_tokenize(s) for s in data] # list of list of sentences\n",
    "    \n",
    "    # remove the stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenized_sentence_filtered = []\n",
    "    # Lemmatizing and removing stopwords\n",
    "    print(\"Lemmatize and remove stopwords\")\n",
    "    for s in tqdm(tokenized_sentence):\n",
    "        tokenized_sentence_filtered.append([WordNetLemmatizer().lemmatize(w.lower(), 'v') for w in s if w not in stop_words])\n",
    "    \n",
    "    tokenized_sentence_filtered, vocabulary, w2i, i2w = get_vocab(tokenized_sentence_filtered, subsampling=subsampling, sampling_rate=sampling_rate)\n",
    "    train_idx_pairs = get_idx_pairs(tokenized_sentence_filtered, w2i, context_size=context_size)\n",
    "    \n",
    "    return train_idx_pairs, vocabulary, w2i, i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9lYTRb2vJSR_"
   },
   "outputs": [],
   "source": [
    "def get_vocab(tokenized_sentence, subsampling, sampling_rate):\n",
    "    \"\"\"\n",
    "    Build vocabulary and perform subsampling\n",
    "    \n",
    "    \"\"\"\n",
    "    vocabulary = {}\n",
    "    w2i = {}\n",
    "    i2w = {}\n",
    "    n_words = 0.0\n",
    "\n",
    "    # Build vocabulary\n",
    "    print(\"Building vocabulary ...\")\n",
    "    for sentence in tqdm(tokenized_sentence):\n",
    "        for token in sentence:\n",
    "            if token not in vocabulary:\n",
    "                vocabulary[token] = 0\n",
    "                i2w[len(w2i)] = token\n",
    "                w2i[token] = len(w2i)\n",
    "            vocabulary[token] += 1\n",
    "            n_words += 1\n",
    "            \n",
    "    if subsampling:\n",
    "        sub_tokenized_sentence = []\n",
    "        for sentence in tokenized_sentence:\n",
    "            subsampling_s = []\n",
    "            for i, token in enumerate(sentence):\n",
    "                freq = vocabulary[token] / n_words\n",
    "                p_w = 1 - np.sqrt(sampling_rate/freq)\n",
    "                \n",
    "                sampling = np.random.sample() # Return random floats in the half-open interval [0.0, 1.0)\n",
    "                if sampling > p_w: # if sampling < p_w, remove the token\n",
    "                    subsampling_s.append(token)\n",
    "            sub_tokenized_sentence.append(subsampling_s)\n",
    "        tokenized_sentence = sub_tokenized_sentence\n",
    "        \n",
    "    return tokenized_sentence, vocabulary, w2i, i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uW5KfRBpJSR_"
   },
   "outputs": [],
   "source": [
    "def get_idx_pairs(tokenized_sentence, w2i, context_size):\n",
    "    \"\"\"\n",
    "    return a list of [center_word, target_word] pairs\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_dat = []\n",
    "    vocab_idx = list(range(len(w2i)))\n",
    "    \n",
    "    # Get idx pairs:\n",
    "    print(\"Getting index pairs ... \")\n",
    "    for sentence in tqdm(tokenized_sentence):\n",
    "        sent_idx = [w2i[word] for word in sentence]\n",
    "        \n",
    "        # for each word treated as center word\n",
    "        for c_pos in range(len(sent_idx)):\n",
    "            # for each window position\n",
    "            for window in range(-context_size, context_size+1):\n",
    "                tar_pos = c_pos + window\n",
    "                if tar_pos < 0 or tar_pos >= len(sent_idx) or tar_pos == c_pos:\n",
    "                    continue\n",
    "                \n",
    "                cen_word_idx = sent_idx[c_pos]\n",
    "                tar_word_idx = sent_idx[tar_pos]\n",
    "                train_dat.append([cen_word_idx, tar_word_idx])\n",
    "                \n",
    "    return train_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "y3NCYgZhJSSA"
   },
   "outputs": [],
   "source": [
    "def get_noise_dist(vocabulary):\n",
    "    \"\"\"\n",
    "    Build noise dist for negative sampling\n",
    "    \"\"\"\n",
    "    word_freqs = np.array(list(vocabulary.values()))\n",
    "    unigram_dist = word_freqs/sum(word_freqs)\n",
    "    noise_dist = torch.from_numpy(unigram_dist**(0.75)/np.sum(unigram_dist**(0.75)))\n",
    "    return noise_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKVgPIMfJSSA"
   },
   "source": [
    "### word2vec dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "K-liZVWfJSSA"
   },
   "outputs": [],
   "source": [
    "class Word2vecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Build dataset for word2vec\n",
    "    \"\"\"\n",
    "    def __init__(self, train_data, vocabulary, word2idx, idx2word):\n",
    "        self.data = torch.tensor(train_data, dtype=torch.long)\n",
    "        self.vocabulary = vocabulary\n",
    "        self.w2i = word2idx\n",
    "        self.i2w = idx2word\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index, 0]\n",
    "        y = self.data[index, 1]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7flEeo3JSSA"
   },
   "source": [
    "### Skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FsfNhlY6JSSB"
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, vocab_size, device, negative_sampling=False, noise_dist=None, negative_samples=5):\n",
    "        super(SkipGram, self).__init__()\n",
    "        \n",
    "        self.embed_input = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embed_context = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.device = device\n",
    "        self.negative_sampling = negative_sampling\n",
    "        self.negative_samples = negative_samples\n",
    "        self.noise_dist = noise_dist\n",
    "        \n",
    "        # Initialize both embedding tables with uniform distribution\n",
    "        self.embed_input.weight.data.uniform_(-1,1)\n",
    "        self.embed_context.weight.data.uniform_(-1,1)\n",
    "        \n",
    "    def forward(self, center_word, context_word):\n",
    "        emb_input = self.embed_input(center_word)\n",
    "        emb_context = self.embed_context(context_word)\n",
    "        out = torch.mul(emb_input, emb_context)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out_loss = F.logsigmoid(out)\n",
    "        \n",
    "        if self.negative_sampling:\n",
    "            if self.noise_dist is None:\n",
    "                noise_dist = torch.ones(self.vocab_size)  \n",
    "            else:\n",
    "                noise_dist = self.noise_dist\n",
    "                \n",
    "            num_neg_samples = context_word.shape[0]*self.negative_samples\n",
    "            negative_example = torch.multinomial(noise_dist, num_neg_samples, replacement = True)\n",
    "            negative_example = negative_example.view(context_word.shape[0], self.negative_samples).to(self.device)\n",
    "            emb_negative = self.embed_context(negative_example)\n",
    "            \n",
    "            emb_product_neg_samples = torch.bmm(emb_negative.neg(), emb_input.unsqueeze(2)) # b * negative_samples * 1\n",
    "            noise_loss = F.logsigmoid(emb_product_neg_samples).squeeze(2).sum(1)\n",
    "            \n",
    "            total_loss = -(out_loss + noise_loss).mean()\n",
    "            \n",
    "            return total_loss\n",
    "        \n",
    "        else:\n",
    "            total_loss = -(out_loss).mean()\n",
    "            return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rODsPlhUJSSB"
   },
   "outputs": [],
   "source": [
    "def train_w2v(model, optimizer, NUM_EPOCHS, DEVICE, train_loader):\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "        print('\\n----- EPOCH {}/{} -----'.format(epoch + 1, NUM_EPOCHS))    \n",
    "\n",
    "        # model.train()\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(x_batch, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if batch_idx % 1000 == 0:\n",
    "                print(f'Batch: {batch_idx+1}/{len(train_loader)}, Loss: {loss.item()}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rC6yoa-JSSC"
   },
   "source": [
    "### bi-Gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FfQeLCNyJSSD"
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, bidirectional=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "\n",
    "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedded = self.embedding(sentence)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        # sequence_len,batch_size, embedding_dim\n",
    "        gru_out, self.hidden = self.gru(embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
    "        out = self.hidden2label(gru_out[-1])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "3SvgCVtIJSSD"
   },
   "outputs": [],
   "source": [
    "def create_gru_dataloader(train_x, val_x, train_y, val_y, train, word2idx=None, embedding=None,\n",
    "                          hidden_size=None, batch_size=None, device=None):\n",
    "    \"\"\"\n",
    "    Return dataloader for training bi-GRU model\n",
    "    \"\"\"\n",
    "    if train:\n",
    "        tokenized_training_x = get_tokenized_corpus(train_x)\n",
    "        tokenized_dev_x = get_tokenized_corpus(val_x)\n",
    "\n",
    "        vectorized_seqs_train = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in tokenized_training_x]\n",
    "        vectorized_seqs_val = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in tokenized_dev_x]\n",
    "\n",
    "        # To avoid any sentences being empty (if no words match to our word embeddings)\n",
    "        vectorized_seqs_train = [x if len(x) > 0 else [0] for x in vectorized_seqs_train]\n",
    "        vectorized_seqs_val = [x if len(x) > 0 else [0] for x in vectorized_seqs_val]\n",
    "\n",
    "        INPUT_DIM = len(word2idx)\n",
    "        EMBEDDING_DIM = embedding.shape[1]\n",
    "        HIDDEN_DIM = hidden_size\n",
    "        BATCH_SIZE = batch_size\n",
    "\n",
    "        gru_model = GRU(EMBEDDING_DIM, HIDDEN_DIM, INPUT_DIM, BATCH_SIZE, device)\n",
    "        print(\"Model initialised.\")\n",
    "\n",
    "        gru_model.to(device)\n",
    "        # We provide the model with our embeddings\n",
    "        gru_model.embedding.weight.data.copy_(embedding)\n",
    "\n",
    "\n",
    "        train_dataset = Task1Dataset(vectorized_seqs_train, train_y.to_numpy())\n",
    "        dev_dataset = Task1Dataset(vectorized_seqs_val, val_y.to_numpy())\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "        dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "        print(\"Dataloaders created.\")\n",
    "        return gru_model, train_loader, dev_loader\n",
    "    else:\n",
    "        # testing\n",
    "        BATCH_SIZE = batch_size\n",
    "        tokenized_dev_x = get_tokenized_corpus(val_x)\n",
    "        \n",
    "        vectorized_seqs_val = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in tokenized_dev_x]\n",
    "        \n",
    "        vectorized_seqs_val = [x if len(x) > 0 else [0] for x in vectorized_seqs_val]\n",
    "        \n",
    "        dev_dataset = Task1Dataset(vectorized_seqs_val, val_y)\n",
    "        \n",
    "        dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "        \n",
    "        return dev_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRLvm_ZFJSSD"
   },
   "source": [
    "## 2-1 Training word-embedding on train+val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4f57f7175abd4851b70621febc5e7d81",
      "afe6d4ccff3d46788ec4f9fb76620eee",
      "e10470982f174ae18760370744c3e1d8"
     ]
    },
    "id": "hqGnYjLzJSSD",
    "outputId": "f728e562-275e-4eb0-f97c-3738dd5abc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatize and remove stopwords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bb5e52a6554e68a5b9d5a850f328bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7eba88f7f7405193d41cdcaf7a314b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting index pairs ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150fda8025de45c99e7d0e8526d97a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare for training set\n",
    "input_data = pd.concat([training_x, dev_x]).values.tolist()\n",
    "train_idx_pairs, vocabulary, w2i, i2w = load_data(input_data, context_size=5, subsampling=False)\n",
    "train_dataset = Word2vecDataset(train_idx_pairs, vocabulary, w2i, i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "cjF8GwCAJSSE",
    "outputId": "4a6a8df0-0593-45ca-ff23-d07277a02dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset):  1460444\n",
      "len(train_loader):  2853\n",
      "len(vocab):  14915 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the dataset info\n",
    "vocab = train_dataset.vocabulary\n",
    "word_to_ix = train_dataset.w2i\n",
    "ix_to_word = train_dataset.i2w\n",
    "noise_dist = get_noise_dist(vocab)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 512, shuffle=True)\n",
    "\n",
    "print('len(train_dataset): ', len(train_dataset))\n",
    "print('len(train_loader): ', len(train_loader))\n",
    "print('len(vocab): ', len(vocab), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weOvFZ3XJSSE",
    "outputId": "99ac3231-af60-435b-f9ea-000c6c753f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram(\n",
      "  (embed_input): Embedding(14915, 100)\n",
      "  (embed_context): Embedding(14915, 100)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialise Skip-gram model\n",
    "sg_model = SkipGram(100, len(vocab), device, negative_sampling=True, noise_dist=noise_dist, negative_samples=15).to(device)\n",
    "sg_optimizer = torch.optim.Adam(sg_model.parameters())\n",
    "print(sg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR32953AJSSF"
   },
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c96e69c3556e4a45b9f8fc731495bd6c"
     ]
    },
    "id": "_P_DC5DGJSSF",
    "outputId": "687fccd1-4094-4c0b-e4be-185307406ecb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96e69c3556e4a45b9f8fc731495bd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- EPOCH 1/10 -----\n",
      "Batch: 1/2853, Loss: 24.303386688232422\n",
      "Batch: 1001/2853, Loss: 15.333587646484375\n",
      "Batch: 2001/2853, Loss: 8.393190383911133\n",
      "\n",
      "----- EPOCH 2/10 -----\n",
      "Batch: 1/2853, Loss: 5.936496734619141\n",
      "Batch: 1001/2853, Loss: 4.773550033569336\n",
      "Batch: 2001/2853, Loss: 4.363983631134033\n",
      "\n",
      "----- EPOCH 3/10 -----\n",
      "Batch: 1/2853, Loss: 4.1367034912109375\n",
      "Batch: 1001/2853, Loss: 3.8732213973999023\n",
      "Batch: 2001/2853, Loss: 3.815312385559082\n",
      "\n",
      "----- EPOCH 4/10 -----\n",
      "Batch: 1/2853, Loss: 3.57132887840271\n",
      "Batch: 1001/2853, Loss: 3.483257532119751\n",
      "Batch: 2001/2853, Loss: 3.4256818294525146\n",
      "\n",
      "----- EPOCH 5/10 -----\n",
      "Batch: 1/2853, Loss: 3.3023521900177\n",
      "Batch: 1001/2853, Loss: 3.2651190757751465\n",
      "Batch: 2001/2853, Loss: 3.292302370071411\n",
      "\n",
      "----- EPOCH 6/10 -----\n",
      "Batch: 1/2853, Loss: 3.103996992111206\n",
      "Batch: 1001/2853, Loss: 3.117640972137451\n",
      "Batch: 2001/2853, Loss: 3.008286714553833\n",
      "\n",
      "----- EPOCH 7/10 -----\n",
      "Batch: 1/2853, Loss: 2.8872735500335693\n",
      "Batch: 1001/2853, Loss: 2.9114251136779785\n",
      "Batch: 2001/2853, Loss: 2.9649524688720703\n",
      "\n",
      "----- EPOCH 8/10 -----\n",
      "Batch: 1/2853, Loss: 2.8059263229370117\n",
      "Batch: 1001/2853, Loss: 2.848200559616089\n",
      "Batch: 2001/2853, Loss: 2.8368144035339355\n",
      "\n",
      "----- EPOCH 9/10 -----\n",
      "Batch: 1/2853, Loss: 2.5970938205718994\n",
      "Batch: 1001/2853, Loss: 2.57186222076416\n",
      "Batch: 2001/2853, Loss: 2.694439172744751\n",
      "\n",
      "----- EPOCH 10/10 -----\n",
      "Batch: 1/2853, Loss: 2.561629295349121\n",
      "Batch: 1001/2853, Loss: 2.7028543949127197\n",
      "Batch: 2001/2853, Loss: 2.62776780128479\n"
     ]
    }
   ],
   "source": [
    "train_w2v(model=sg_model, optimizer=sg_optimizer, NUM_EPOCHS=10, DEVICE=device, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDgFq_1-JSSF",
    "outputId": "aa3fb086-365c-473e-b9b4-6485a4b36d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS.shape:  torch.Size([14915, 100])\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_1 = sg_model.embed_input.weight.data\n",
    "print('EMBEDDINGS.shape: ', EMBEDDINGS_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99YOEs06JSSG"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(sg_model.state_dict(), 'w2v_origin.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orTGwDWtJSSG"
   },
   "source": [
    "#### Train bi-Gru Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-8HxPjDJSSH",
    "outputId": "0038fb59-7414-4d83-b8e7-f195021dcf03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialised.\n",
      "Dataloaders created.\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.58 | Train MSE: 0.58 | Train RMSE: 0.76 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |             Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |             Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |             Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 09 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |             Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |             Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "hidden_dim = 50\n",
    "filename = ['./results/train_loss_1.npy', './results/val_loss_1.npy']\n",
    "is_train = True\n",
    "gru_model, train_loader, dev_loader = create_gru_dataloader(training_x, dev_x, training_y, dev_y, is_train, w2i, EMBEDDINGS_1, hidden_dim, batch_size, device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.0001)\n",
    "\n",
    "train(train_loader, dev_loader, gru_model, epochs, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHgasgAuJSSH",
    "outputId": "1f402d50-72b7-4894-c224-3c085934f3e4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "train_loss = np.load('./results/train_loss_1.npy')\n",
    "eval_loss = np.load('./results/val_loss_1.npy')\n",
    "x = list(range(len(train_loss)))\n",
    "plt.plot(x, train_loss)\n",
    "plt.plot(x, eval_loss)\n",
    "plt.legend(['train loss', 'eval loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(linestyle='--')\n",
    "plt.show()\n",
    "plt.savefig('./results/bigru-1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T99BgKSsJSSH"
   },
   "source": [
    "### Performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBKk0-kxJSSj",
    "outputId": "c2088e1d-82af-413b-88c5-26bfe26d7231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the test samples: 3024\n",
      "whole test data, test loss 0.354736, test rmse 0.595597\n",
      "0.100000 test data, test loss 0.918842, test rmse 0.958563\n",
      "0.200000 test data, test loss 0.664310, test rmse 0.815052\n",
      "0.300000 test data, test loss 0.509828, test rmse 0.714023\n",
      "0.400000 test data, test loss 0.404516, test rmse 0.636016\n"
     ]
    }
   ],
   "source": [
    "test_df = edited_test_df.sort_values(by=['meanGrade'])\n",
    "test_x = test_df['edited']\n",
    "test_y = test_df['meanGrade']\n",
    "n_samples = edited_test_df.shape[0]\n",
    "print('Number of the test samples: {}'.format(n_samples))\n",
    "\n",
    "test10 = pd.concat([test_df[:int(0.1*n_samples)], test_df[int(0.9*n_samples):]], ignore_index=True)\n",
    "test20 = pd.concat([test_df[:int(0.2*n_samples)], test_df[int(0.8*n_samples):]], ignore_index=True)\n",
    "test30 = pd.concat([test_df[:int(0.3*n_samples)], test_df[int(0.7*n_samples):]], ignore_index=True)\n",
    "test40 = pd.concat([test_df[:int(0.4*n_samples)], test_df[int(0.6*n_samples):]], ignore_index=True)\n",
    "\n",
    "test_loader = create_gru_dataloader(None, test_x, None, test_y, train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader10 = create_gru_dataloader(None, test10['edited'], None, test10['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader20 = create_gru_dataloader(None, test20['edited'], None, test20['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader30 = create_gru_dataloader(None, test30['edited'], None, test30['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader40 = create_gru_dataloader(None, test40['edited'], None, test40['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "\n",
    "loaders = [test_loader, test_loader10, test_loader20, test_loader30, test_loader40]\n",
    "\n",
    "for i, loader in enumerate(loaders):\n",
    "    test_loss, test_mse, __, __ = eval(loader, gru_model)\n",
    "    if i == 0:\n",
    "        print('whole test data, test loss {:.6f}, test rmse {:.6f}'.format(test_loss, test_mse**0.5))\n",
    "    else:\n",
    "        print('{:2f} test data, test loss {:.6f}, test rmse {:.6f}'.format(0.1*i, test_loss, test_mse**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw4T9GCMJSSk"
   },
   "source": [
    "## Train the embedding on larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQwgLnfiJSSk"
   },
   "source": [
    "Hlper function to pre-process text8 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Bmh4UMVxJSSk"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import gensim.downloader as api\n",
    "\n",
    "def process_text8(fraction_data):\n",
    "    dataset = api.load(\"text8\")\n",
    "    data = [d for d in dataset][:int(fraction_data*len([d_ for d_ in dataset]))]\n",
    "    print(f'fraction of data taken: {fraction_data}/1')\n",
    "\n",
    "    sents = []\n",
    "    for d in tqdm(data):\n",
    "        sents.append(' '.join(d))\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "7e4f5f873b4240649d9f9b372545aac5"
     ]
    },
    "id": "sWqVVxyKJSSk",
    "outputId": "8669ddff-8036-424b-9e5c-839b968664e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of data taken: 0.2/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76afa5780f314d529faaccd0adeeb3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20659\n"
     ]
    }
   ],
   "source": [
    "text8 = process_text8(fraction_data=0.2)\n",
    "total = text8 + input_data\n",
    "print(len(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLfU0rEqJSSl"
   },
   "source": [
    "### Train the skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "0366ed3136b5494c8233f35d6d911569",
      "1f71fb93518b47f087b1679ba60e60fe",
      "abdbfb6656db4c37a7d79d8acc30a039"
     ]
    },
    "id": "TK_wwJZWJSSl",
    "outputId": "c2c3ee10-f215-4e41-a42a-92251bda20af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatize and remove stopwords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5347dfe58d41478a8d2a9d49a8e975e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ff010e588648e4b9df6ce60a636755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting index pairs ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb565fa27be4576b36f60f5f4ed0f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset):  7516988\n",
      "len(train_loader):  7341\n",
      "len(vocab):  97090 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_idx_pairs_2, vocabulary_2, w2i_2, i2w_2 = load_data(total, context_size=5, subsampling=True, sampling_rate=1e-5)\n",
    "train_dataset_2 = Word2vecDataset(train_idx_pairs_2, vocabulary_2, w2i_2, i2w_2)\n",
    "\n",
    "vocab_2 = train_dataset_2.vocabulary\n",
    "word_to_ix_2 = train_dataset_2.w2i\n",
    "ix_to_word_2 = train_dataset_2.i2w\n",
    "\n",
    "train_loader_2 = torch.utils.data.DataLoader(train_dataset_2, batch_size = 1024, shuffle=True)\n",
    "\n",
    "print('len(train_dataset): ', len(train_dataset_2))\n",
    "print('len(train_loader): ', len(train_loader_2))\n",
    "print('len(vocab): ', len(vocab_2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "4ep8mwafJSSl",
    "outputId": "5d457aa6-2621-4266-975f-6bd34073f804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram(\n",
      "  (embed_input): Embedding(97090, 100)\n",
      "  (embed_context): Embedding(97090, 100)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "noise_dist_2 = get_noise_dist(vocab_2)\n",
    "sg_model_2 = SkipGram(100, len(vocab_2), device, negative_sampling=True, noise_dist=noise_dist_2, negative_samples=15).to(device)\n",
    "print(sg_model_2)\n",
    "sg_optimizer_2 = torch.optim.Adam(sg_model_2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "235e310b95d34e4a9235e399bf24cf07"
     ]
    },
    "id": "zBJBrMMSJSSm",
    "outputId": "f4e1972d-a5ed-4aa5-b614-64be7e53fcfc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d7fcdb5a544a458b4a99ca1ccc1a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- EPOCH 1/10 -----\n",
      "Batch: 1/7341, Loss: 23.91849136352539\n",
      "Batch: 1001/7341, Loss: 20.91864013671875\n",
      "Batch: 2001/7341, Loss: 17.07882308959961\n",
      "Batch: 3001/7341, Loss: 11.770743370056152\n",
      "Batch: 4001/7341, Loss: 8.916692733764648\n",
      "Batch: 5001/7341, Loss: 6.966709136962891\n",
      "Batch: 6001/7341, Loss: 5.8596954345703125\n",
      "Batch: 7001/7341, Loss: 5.186636447906494\n",
      "\n",
      "----- EPOCH 2/10 -----\n",
      "Batch: 1/7341, Loss: 5.0143327713012695\n",
      "Batch: 1001/7341, Loss: 4.572483062744141\n",
      "Batch: 2001/7341, Loss: 4.429664611816406\n",
      "Batch: 3001/7341, Loss: 4.316624164581299\n",
      "Batch: 4001/7341, Loss: 4.1544189453125\n",
      "Batch: 5001/7341, Loss: 4.105058670043945\n",
      "Batch: 6001/7341, Loss: 3.970726490020752\n",
      "Batch: 7001/7341, Loss: 3.937100410461426\n",
      "\n",
      "----- EPOCH 3/10 -----\n",
      "Batch: 1/7341, Loss: 3.6076204776763916\n",
      "Batch: 1001/7341, Loss: 3.5502591133117676\n",
      "Batch: 2001/7341, Loss: 3.5871686935424805\n",
      "Batch: 3001/7341, Loss: 3.493351936340332\n",
      "Batch: 4001/7341, Loss: 3.5506932735443115\n",
      "Batch: 5001/7341, Loss: 3.5082240104675293\n",
      "Batch: 6001/7341, Loss: 3.504995584487915\n",
      "Batch: 7001/7341, Loss: 3.436424970626831\n",
      "\n",
      "----- EPOCH 4/10 -----\n",
      "Batch: 1/7341, Loss: 3.180450916290283\n",
      "Batch: 1001/7341, Loss: 3.150473117828369\n",
      "Batch: 2001/7341, Loss: 3.133373260498047\n",
      "Batch: 3001/7341, Loss: 3.151097536087036\n",
      "Batch: 4001/7341, Loss: 3.0969953536987305\n",
      "Batch: 5001/7341, Loss: 3.1288390159606934\n",
      "Batch: 6001/7341, Loss: 3.0937376022338867\n",
      "Batch: 7001/7341, Loss: 2.998469829559326\n",
      "\n",
      "----- EPOCH 5/10 -----\n",
      "Batch: 1/7341, Loss: 2.8332290649414062\n",
      "Batch: 1001/7341, Loss: 2.8629181385040283\n",
      "Batch: 2001/7341, Loss: 2.7469863891601562\n",
      "Batch: 3001/7341, Loss: 2.849184989929199\n",
      "Batch: 4001/7341, Loss: 2.8110063076019287\n",
      "Batch: 5001/7341, Loss: 2.7875866889953613\n",
      "Batch: 6001/7341, Loss: 2.692066192626953\n",
      "Batch: 7001/7341, Loss: 2.700265884399414\n",
      "\n",
      "----- EPOCH 6/10 -----\n",
      "Batch: 1/7341, Loss: 2.596177577972412\n",
      "Batch: 1001/7341, Loss: 2.5750021934509277\n",
      "Batch: 2001/7341, Loss: 2.5319271087646484\n",
      "Batch: 3001/7341, Loss: 2.4540205001831055\n",
      "Batch: 4001/7341, Loss: 2.5838968753814697\n",
      "Batch: 5001/7341, Loss: 2.5921401977539062\n",
      "Batch: 6001/7341, Loss: 2.5820255279541016\n",
      "Batch: 7001/7341, Loss: 2.596402645111084\n",
      "\n",
      "----- EPOCH 7/10 -----\n",
      "Batch: 1/7341, Loss: 2.3644700050354004\n",
      "Batch: 1001/7341, Loss: 2.337252616882324\n",
      "Batch: 2001/7341, Loss: 2.3945236206054688\n",
      "Batch: 3001/7341, Loss: 2.421719551086426\n",
      "Batch: 4001/7341, Loss: 2.5210721492767334\n",
      "Batch: 5001/7341, Loss: 2.4932379722595215\n",
      "Batch: 6001/7341, Loss: 2.4321203231811523\n",
      "Batch: 7001/7341, Loss: 2.497317314147949\n",
      "\n",
      "----- EPOCH 8/10 -----\n",
      "Batch: 1/7341, Loss: 2.32962703704834\n",
      "Batch: 1001/7341, Loss: 2.253505229949951\n",
      "Batch: 2001/7341, Loss: 2.283169746398926\n",
      "Batch: 3001/7341, Loss: 2.2657999992370605\n",
      "Batch: 4001/7341, Loss: 2.3281803131103516\n",
      "Batch: 5001/7341, Loss: 2.3146440982818604\n",
      "Batch: 6001/7341, Loss: 2.3793530464172363\n",
      "Batch: 7001/7341, Loss: 2.3283092975616455\n",
      "\n",
      "----- EPOCH 9/10 -----\n",
      "Batch: 1/7341, Loss: 2.161301612854004\n",
      "Batch: 1001/7341, Loss: 2.1775007247924805\n",
      "Batch: 2001/7341, Loss: 2.146925687789917\n",
      "Batch: 3001/7341, Loss: 2.3159584999084473\n",
      "Batch: 4001/7341, Loss: 2.1827640533447266\n",
      "Batch: 5001/7341, Loss: 2.1816723346710205\n",
      "Batch: 6001/7341, Loss: 2.2418065071105957\n",
      "Batch: 7001/7341, Loss: 2.2682268619537354\n",
      "\n",
      "----- EPOCH 10/10 -----\n",
      "Batch: 1/7341, Loss: 2.049561023712158\n",
      "Batch: 1001/7341, Loss: 2.064530372619629\n",
      "Batch: 2001/7341, Loss: 2.1810436248779297\n",
      "Batch: 3001/7341, Loss: 2.103208541870117\n",
      "Batch: 4001/7341, Loss: 2.0305187702178955\n",
      "Batch: 5001/7341, Loss: 2.1713500022888184\n",
      "Batch: 6001/7341, Loss: 2.162968158721924\n",
      "Batch: 7001/7341, Loss: 2.1333484649658203\n"
     ]
    }
   ],
   "source": [
    "train_w2v(model=sg_model_2, optimizer=sg_optimizer_2, NUM_EPOCHS=10, DEVICE=device, train_loader=train_loader_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "CAJ4bje3JSSm",
    "outputId": "fa1dd7b1-3cc1-4ee7-bf80-4b6ee406d656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS.shape:  torch.Size([97090, 100])\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_2 = sg_model_2.embed_input.weight.data\n",
    "print('EMBEDDINGS.shape: ', EMBEDDINGS_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "rs4IDHRuJSSm"
   },
   "outputs": [],
   "source": [
    "# save the embedding\n",
    "torch.save(sg_model_2.state_dict(), 'w2v_sg_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "VViEaysdJSSn",
    "outputId": "4b70396e-d047-4e52-fce8-c21d040e6422",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialised.\n",
      "Dataloaders created.\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.51 | Train MSE: 0.51 | Train RMSE: 0.71 |             Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |             Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |             Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |             Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |             Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n"
     ]
    }
   ],
   "source": [
    "# Train bi-gru model\n",
    "epochs = 8\n",
    "batch_size = 64\n",
    "hidden_dim = 50\n",
    "filename = ['./results/train_loss_2.npy', './results/val_loss_2.npy']\n",
    "is_train = True\n",
    "gru_model_2, train_loader_2, dev_loader_2 = create_gru_dataloader(training_x, dev_x, training_y, dev_y, is_train, w2i_2, EMBEDDINGS_2, hidden_dim, batch_size, device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "optimizer = torch.optim.Adam(gru_model_2.parameters(), lr=0.0001)\n",
    "\n",
    "train(train_loader_2, dev_loader_2, gru_model_2, epochs, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "DuatUcjMJSSn"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(gru_model_2.state_dict(), './results/bigru-2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "2OBhCCnAJSSn",
    "outputId": "a69956bc-9128-4497-db09-b06905234826",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "train_loss = np.load('./results/train_loss_2.npy')\n",
    "eval_loss = np.load('./results/val_loss_2.npy')\n",
    "x = list(range(len(train_loss)))\n",
    "plt.plot(x, train_loss)\n",
    "plt.plot(x, eval_loss)\n",
    "plt.legend(['train loss', 'eval loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(linestyle='--')\n",
    "plt.savefig('./results/bigru-2.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ookr93aBJSSz"
   },
   "source": [
    "### Performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "A9Cc8BOzJSS0",
    "outputId": "0e8dda92-8081-4e4a-be95-a6fe18c26211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the test samples: 3024\n",
      "whole test data, test loss 0.336131, test rmse 0.579768\n",
      "0.100000 test data, test loss 0.975938, test rmse 0.987896\n",
      "0.200000 test data, test loss 0.694871, test rmse 0.833589\n",
      "0.300000 test data, test loss 0.528296, test rmse 0.726839\n",
      "0.400000 test data, test loss 0.413420, test rmse 0.642978\n"
     ]
    }
   ],
   "source": [
    "test_df = edited_test_df.sort_values(by=['meanGrade'])\n",
    "test_x = test_df['edited']\n",
    "test_y = test_df['meanGrade']\n",
    "n_samples = edited_test_df.shape[0]\n",
    "print('Number of the test samples: {}'.format(n_samples))\n",
    "\n",
    "test10 = pd.concat([test_df[:int(0.1*n_samples)], test_df[int(0.9*n_samples):]], ignore_index=True)\n",
    "test20 = pd.concat([test_df[:int(0.2*n_samples)], test_df[int(0.8*n_samples):]], ignore_index=True)\n",
    "test30 = pd.concat([test_df[:int(0.3*n_samples)], test_df[int(0.7*n_samples):]], ignore_index=True)\n",
    "test40 = pd.concat([test_df[:int(0.4*n_samples)], test_df[int(0.6*n_samples):]], ignore_index=True)\n",
    "\n",
    "test_loader = create_gru_dataloader(None, test_x, None, test_y, train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader10 = create_gru_dataloader(None, test10['edited'], None, test10['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader20 = create_gru_dataloader(None, test20['edited'], None, test20['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader30 = create_gru_dataloader(None, test30['edited'], None, test30['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "test_loader40 = create_gru_dataloader(None, test40['edited'], None, test40['meanGrade'], train=False, word2idx=w2i, batch_size=128)\n",
    "\n",
    "loaders = [test_loader, test_loader10, test_loader20, test_loader30, test_loader40]\n",
    "\n",
    "for i, loader in enumerate(loaders):\n",
    "    test_loss, test_mse, __, __ = eval(loader, gru_model_2)\n",
    "    if i == 0:\n",
    "        print('whole test data, test loss {:.6f}, test rmse {:.6f}'.format(test_loss, test_mse**0.5))\n",
    "    else:\n",
    "        print('{:2f} test data, test loss {:.6f}, test rmse {:.6f}'.format(0.1*i, test_loss, test_mse**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quaXNAT-JSS0"
   },
   "source": [
    "### save dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Cdq1jMuTJSS0"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_dict(dictionary, filename):\n",
    "    name = filename + '.pkl'\n",
    "    a_file = open(name, \"wb\")\n",
    "    pickle.dump(dictionary, a_file)\n",
    "    a_file.close()\n",
    "    \n",
    "def load_dict(path):\n",
    "    a_file = open(path, \"rb\")\n",
    "    output = pickle.load(a_file)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "FzotowyJJSS1"
   },
   "outputs": [],
   "source": [
    "save_dict(vocabulary, './results/vocabulary-1')\n",
    "save_dict(vocabulary_2, './results/vocabulary-2')\n",
    "save_dict(w2i, './results/w2i-1')\n",
    "save_dict(w2i_2, './results/w2i-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task_1_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
